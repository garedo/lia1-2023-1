{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-07T00:41:00.269667Z","iopub.execute_input":"2023-08-07T00:41:00.270194Z","iopub.status.idle":"2023-08-07T00:41:14.445934Z","shell.execute_reply.started":"2023-08-07T00:41:00.270155Z","shell.execute_reply":"2023-08-07T00:41:14.444561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport tensorflow as tf\nfrom transformers import BertTokenizer\nfrom nltk.corpus import stopwords\nfrom contextlib import redirect_stdout\nimport keras\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom transformers import TFBertModel","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:28:22.904876Z","iopub.execute_input":"2023-08-13T23:28:22.905428Z","iopub.status.idle":"2023-08-13T23:28:40.790447Z","shell.execute_reply.started":"2023-08-13T23:28:22.905366Z","shell.execute_reply":"2023-08-13T23:28:40.788884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/tweet-analise-sentimento/analise_sentimento_dataset.csv\")\ndataset[\"id\"] = dataset.index + 1","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:28:40.793703Z","iopub.execute_input":"2023-08-13T23:28:40.794876Z","iopub.status.idle":"2023-08-13T23:28:41.253094Z","shell.execute_reply.started":"2023-08-13T23:28:40.794820Z","shell.execute_reply":"2023-08-13T23:28:41.251577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.sample(frac = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:28:49.146046Z","iopub.execute_input":"2023-08-13T23:28:49.146482Z","iopub.status.idle":"2023-08-13T23:28:49.180021Z","shell.execute_reply.started":"2023-08-13T23:28:49.146447Z","shell.execute_reply":"2023-08-13T23:28:49.177794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = dataset[0:49893]\ntest = dataset[49893:]","metadata":{"execution":{"iopub.status.busy":"2023-08-13T23:29:08.564179Z","iopub.execute_input":"2023-08-13T23:29:08.564631Z","iopub.status.idle":"2023-08-13T23:29:08.572254Z","shell.execute_reply.started":"2023-08-13T23:29:08.564594Z","shell.execute_reply":"2023-08-13T23:29:08.570046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['tweet_text'] = df['tweet_text'].str.replace(':', '')\ndf['tweet_text'] = df['tweet_text'].str.replace(')', '')\ndf['tweet_text'] = df['tweet_text'].str.replace('(', '')","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:58:24.064006Z","iopub.execute_input":"2023-08-10T22:58:24.064400Z","iopub.status.idle":"2023-08-10T22:58:24.166557Z","shell.execute_reply.started":"2023-08-10T22:58:24.064368Z","shell.execute_reply":"2023-08-10T22:58:24.164258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased')","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:13:44.582012Z","iopub.execute_input":"2023-08-07T01:13:44.582580Z","iopub.status.idle":"2023-08-07T01:13:44.863510Z","shell.execute_reply.started":"2023-08-07T01:13:44.582538Z","shell.execute_reply":"2023-08-07T01:13:44.862497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TFBertModel.from_pretrained('bert-base-cased') # bert base model with predfed weights","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:13:44.865143Z","iopub.execute_input":"2023-08-07T01:13:44.866361Z","iopub.status.idle":"2023-08-07T01:13:48.560534Z","shell.execute_reply.started":"2023-08-07T01:13:44.866321Z","shell.execute_reply":"2023-08-07T01:13:48.559107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_input_ids = np.zeros((len(df), 256))\nX_attn_masks = np.zeros((len(df), 256))","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:13:48.562995Z","iopub.execute_input":"2023-08-07T01:13:48.563398Z","iopub.status.idle":"2023-08-07T01:13:48.569526Z","shell.execute_reply.started":"2023-08-07T01:13:48.563363Z","shell.execute_reply":"2023-08-07T01:13:48.568416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_training_data(df, ids, masks, tokenizer):\n    for i, text in tqdm(enumerate(df['tweet_text'])):\n        tokenized_text = tokenizer.encode_plus(\n            text,\n            max_length=256, \n            truncation=True, \n            padding='max_length', \n            add_special_tokens=True,\n            return_tensors='tf'\n        )\n        ids[i, :] = tokenized_text.input_ids\n        masks[i, :] = tokenized_text.attention_mask\n    return ids, masks\n\ndef prepare_data(input_text, tokenizer):\n    token = tokenizer.encode_plus(\n        input_text,\n        max_length=256, \n        truncation=True, \n        padding='max_length', \n        add_special_tokens=True,\n        return_tensors='tf'\n    )\n    return {\n        'input_ids': tf.cast(token.input_ids, tf.float64),\n        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n    }","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:13:48.570890Z","iopub.execute_input":"2023-08-07T01:13:48.571298Z","iopub.status.idle":"2023-08-07T01:13:48.586903Z","shell.execute_reply.started":"2023-08-07T01:13:48.571265Z","shell.execute_reply":"2023-08-07T01:13:48.585577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_input_ids, X_attn_masks = generate_training_data(df, X_input_ids, X_attn_masks, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:13:48.590533Z","iopub.execute_input":"2023-08-07T01:13:48.590986Z","iopub.status.idle":"2023-08-07T01:14:36.760467Z","shell.execute_reply.started":"2023-08-07T01:13:48.590948Z","shell.execute_reply":"2023-08-07T01:14:36.758938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = np.zeros((len(df), 3))\nlabels.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:36.761999Z","iopub.execute_input":"2023-08-07T01:14:36.762413Z","iopub.status.idle":"2023-08-07T01:14:36.772454Z","shell.execute_reply.started":"2023-08-07T01:14:36.762380Z","shell.execute_reply":"2023-08-07T01:14:36.771110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels[np.arange(len(df)), df['labels'].values.tolist()] = 1 # one-hot encoded target tensor","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:36.774492Z","iopub.execute_input":"2023-08-07T01:14:36.774925Z","iopub.status.idle":"2023-08-07T01:14:36.795689Z","shell.execute_reply.started":"2023-08-07T01:14:36.774892Z","shell.execute_reply":"2023-08-07T01:14:36.794490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(labels, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:36.797604Z","iopub.execute_input":"2023-08-07T01:14:36.797994Z","iopub.status.idle":"2023-08-07T01:14:36.939596Z","shell.execute_reply.started":"2023-08-07T01:14:36.797961Z","shell.execute_reply":"2023-08-07T01:14:36.938189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:56:02.366440Z","iopub.execute_input":"2023-08-10T22:56:02.366810Z","iopub.status.idle":"2023-08-10T22:56:02.382671Z","shell.execute_reply.started":"2023-08-10T22:56:02.366782Z","shell.execute_reply":"2023-08-10T22:56:02.381182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))\ndataset.take(0) # one sample data","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:36.966412Z","iopub.execute_input":"2023-08-07T01:14:36.966794Z","iopub.status.idle":"2023-08-07T01:14:37.212978Z","shell.execute_reply.started":"2023-08-07T01:14:36.966761Z","shell.execute_reply":"2023-08-07T01:14:37.211497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SentimentDatasetMapFunction(input_ids, attn_masks, labels):\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attn_masks\n    }, labels","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:37.218570Z","iopub.execute_input":"2023-08-07T01:14:37.219176Z","iopub.status.idle":"2023-08-07T01:14:37.226211Z","shell.execute_reply.started":"2023-08-07T01:14:37.219117Z","shell.execute_reply":"2023-08-07T01:14:37.224919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(SentimentDatasetMapFunction) # converting to required format for tensorflow dataset ","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:37.227914Z","iopub.execute_input":"2023-08-07T01:14:37.228414Z","iopub.status.idle":"2023-08-07T01:14:37.255533Z","shell.execute_reply.started":"2023-08-07T01:14:37.228371Z","shell.execute_reply":"2023-08-07T01:14:37.254089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.shuffle(10000).batch(16, drop_remainder=True) # batch size, drop any left out tensor","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:37.257971Z","iopub.execute_input":"2023-08-07T01:14:37.258505Z","iopub.status.idle":"2023-08-07T01:14:37.266360Z","shell.execute_reply.started":"2023-08-07T01:14:37.258461Z","shell.execute_reply":"2023-08-07T01:14:37.264923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = 0.8\ndf_size = int((len(df)//16)*p) # for each 16 batch of data we will have len(df)//16 samples, take 80% of that for df.","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:37.268542Z","iopub.execute_input":"2023-08-07T01:14:37.269084Z","iopub.status.idle":"2023-08-07T01:14:37.280526Z","shell.execute_reply.started":"2023-08-07T01:14:37.269014Z","shell.execute_reply":"2023-08-07T01:14:37.279250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_dataset = dataset.take(df_size)\nval_dataset = dataset.skip(df_size)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:37.282164Z","iopub.execute_input":"2023-08-07T01:14:37.283072Z","iopub.status.idle":"2023-08-07T01:14:37.296301Z","shell.execute_reply.started":"2023-08-07T01:14:37.282994Z","shell.execute_reply":"2023-08-07T01:14:37.295212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params = [{'dense': 32, 'learning_rate': 1e-5*16}, {'dense': 64, 'learning_rate': 1e-5*8}]\n# params = [{'dense': 128, 'learning_rate': 1e-5*4},{'dense': 256, 'learning_rate': 1e-5*2}]\n# params = [{'dense': 512, 'learning_rate': 1e-5}, {'dense': 1024, 'learning_rate': 1e-5/2}]\nparams = [{'dense': 256, 'learning_rate': 1e-5*2}]","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:37.297881Z","iopub.execute_input":"2023-08-07T01:14:37.298365Z","iopub.status.idle":"2023-08-07T01:14:37.310892Z","shell.execute_reply.started":"2023-08-07T01:14:37.298323Z","shell.execute_reply":"2023-08-07T01:14:37.309599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in params:\n    print('Inicio do processo com o modelo de ' + str(param['dense']) + ' camadas')\n    \n    # defining 2 input dense for input_ids and attn_masks\n    input_ids = tf.keras.Input(shape=(256,), name='input_ids', dtype='int32')\n    attn_masks = tf.keras.Input(shape=(256,), name='attention_mask', dtype='int32')\n\n    bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1]\n    intermediate_layer = tf.keras.layers.Dense(param['dense'], activation='relu', name='intermediate_layer')(bert_embds)\n    output_layer = tf.keras.layers.Dense(3, activation='softmax', name='output_layer')(intermediate_layer)\n\n    rr_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n    rr_model.summary()\n    \n    with open('/kaggle/working/' + str(param['dense']) + '_modelsummary.csv', 'w') as f:\n        with redirect_stdout(f):\n            rr_model.summary()\n            \n    print('Summary exportado')\n    \n    optim = tf.keras.optimizers.legacy.Adam(learning_rate=param['learning_rate'], decay=1e-6)\n    loss_func = tf.keras.losses.CategoricalCrossentropy()\n    acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n    \n    rr_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])\n    \n    print('Treinamento iniciado')\n        hist = rr_model.fit(\n        df_dataset,\n        validation_data=val_dataset,\n        epochs=2\n    )\n    \n    rr_model.save('/kaggle/working/' + str(param['dense']) + '_lia_model.h5')    ","metadata":{"execution":{"iopub.status.busy":"2023-08-07T01:14:37.312749Z","iopub.execute_input":"2023-08-07T01:14:37.313172Z","iopub.status.idle":"2023-08-07T01:15:57.474161Z","shell.execute_reply.started":"2023-08-07T01:14:37.313139Z","shell.execute_reply":"2023-08-07T01:15:57.471896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out =[]\nfor i in test['tweet_text']:\n    pred = model.predict(prepare_data(i, tokenizer))\n    out.append(np.argmax(pred).tolist())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = test[\"labels\"].tolist()\ny_pred = out\nmetrics = classification_report(y_true, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negativo', 'Positivo','Neutro'])\ndisp.plot(cmap=plt.cm.Blues)","metadata":{},"execution_count":null,"outputs":[]}]}
